{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:40:25.764352Z",
     "start_time": "2017-11-17T09:40:24.220082Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from stack_nlp import *\n",
    "from jupyter_mplsettings import *\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:40:26.500119Z",
     "start_time": "2017-11-17T09:40:26.490554Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = local_import(\"./laptop.py\")\n",
    "cfg.options[\"read\"] = [\"questions\", \"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:41:04.921467Z",
     "start_time": "2017-11-17T09:40:27.441116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question df (1696819, 21)\n",
      "Shape of merged df (1000000, 34)\n",
      "Selecting only questions with at least 5 meaningful words.\n",
      "This removes 8582 questions.\n",
      "Removing bad values with missing feature information.\n",
      "This affects 19 questions.\n",
      "Shape of answer df (2028240, 21)\n",
      "Information from answer df was merged into question df, but original df is trying to be closed and deleted from memory! Please change the config options to keep it open!\n",
      "Calculating normalized columns. They are available under usual column name + _norm.\n"
     ]
    }
   ],
   "source": [
    "PrepareData(cfg)\n",
    "data = cfg.data\n",
    "data.keys()\n",
    "qs = data[\"meta\"]\n",
    "conn = data[\"dbconn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T09:43:46.287093Z",
     "start_time": "2017-11-17T09:41:18.833800Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_dim = 300\n",
    "embeddings_path = \"/home/alex/data/glove.6B.%id.txt\" % embed_dim\n",
    "word2vec_output_file = \"./glove.6B.%id.txt.word2vec\" % embed_dim\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "gensimmodel = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-16T14:27:49.988949Z",
     "start_time": "2017-11-16T14:27:49.978395Z"
    }
   },
   "outputs": [],
   "source": [
    "def GetAnswerTimeQuantiles(df, ncat):\n",
    "    timecat_bins = np.linspace(-0.5, ncat + 0.5, ncat + 2)\n",
    "\n",
    "    tmask = np.isfinite(df.dt_accanswer_hour)\n",
    "    time_categories = mquantiles(df.loc[tmask].dt_accanswer_hour, prob=np.linspace(0, 1, ncat + 1))\n",
    "    return time_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-16T14:31:13.032025Z",
     "start_time": "2017-11-16T14:31:13.024367Z"
    }
   },
   "outputs": [],
   "source": [
    "def AddTimeCategories(df, timequants):\n",
    "    tmask = np.isfinite(df.dt_accanswer_hour)\n",
    "    df[\"timecat\"] = 0\n",
    "    df.loc[tmask, \"timecat\"] = np.digitize(df.loc[tmask].dt_accanswer_hour, timequants) - 1\n",
    "    df.loc[~tmask, \"timecat\"] = len(timequants) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-16T14:53:51.862586Z",
     "start_time": "2017-11-16T14:53:51.849855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: goodscore, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs[\"goodscore\"] = np.asarray(qs.Score > 0, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:27:41.116263Z",
     "start_time": "2017-11-17T10:27:40.788101Z"
    }
   },
   "outputs": [],
   "source": [
    "qs[\"ispython\"] = qs.Tags.apply(lambda x: \"python\" in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:27:52.691770Z",
     "start_time": "2017-11-17T10:27:51.697696Z"
    }
   },
   "outputs": [],
   "source": [
    "qssel = SelectUniformlyFromColumn(qs, \"ispython\", n=150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:28:02.696968Z",
     "start_time": "2017-11-17T10:28:02.688743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the training set: 100000\n",
      "Length of the testing set: 50000\n"
     ]
    }
   ],
   "source": [
    "train = 100000\n",
    "test = 50000\n",
    "qstrain = qssel.iloc[:train]\n",
    "qstest = qssel.iloc[-test:]\n",
    "print \"Length of the training set:\", len(qstrain)\n",
    "print \"Length of the testing set:\", len(qstest)\n",
    "\n",
    "# label = \"dt_accanswer_hour\"\n",
    "# label = \"timecat\"\n",
    "# label = \"quickanswer\"\n",
    "# label = \"goodscore\"\n",
    "label = \"ispython\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:28:40.113012Z",
     "start_time": "2017-11-17T10:28:16.120103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "posts_train = GetDBPosts(qstrain.Id.values, conn)\n",
    "posts_test = GetDBPosts(qstest.Id.values, conn)\n",
    "print len(posts_train)\n",
    "print len(posts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:29:28.870203Z",
     "start_time": "2017-11-17T10:29:28.865336Z"
    }
   },
   "outputs": [],
   "source": [
    "titles_train = np.squeeze(qstrain.Title.values)\n",
    "titles_test = np.squeeze(qstest.Title.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-16T17:13:12.645618Z",
     "start_time": "2017-11-16T17:13:12.642197Z"
    }
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:49:39.212695Z",
     "start_time": "2017-11-17T10:48:29.270002Z"
    }
   },
   "outputs": [],
   "source": [
    "# limiting the number of features / words and setting up the tokenizer\n",
    "max_features = 50000\n",
    "\n",
    "word_tokenizer = Tokenizer(max_features)\n",
    "word_tokenizer.fit_on_texts(posts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:51:28.337456Z",
     "start_time": "2017-11-17T10:50:26.483695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1    85    12    24     2    33   904     1     9     2  1060    16\n",
      "  1508    31    31  1508   142    78   217    25  6807  1156    25    36\n",
      "    25 11464    25  2820    25 16224  3091 23057    17   914   174     6\n",
      "     3    31   856    78  5987    25    36    25    36    36    78    25\n",
      " 11464    25 11464 11464    78    25  2820    25  2820  2820    78    25\n",
      " 16224    25 16224 16224  5276 23057    17   317   174    16     3    31\n",
      "   856    78  2709    25    47    25    36    78    25    47    25 11464\n",
      "    78    25    47    25  2820    78    25    47    25 16224 23057    92\n",
      "   910   142    33    65   849    14   320   414   856    78   320  3491\n",
      "   142    56    36  3491   142  2709    56 11464  3491   142    56  2820\n",
      "  3491   142    56 16224  3491   142   157 23057    16     3   296    21\n",
      "    36   157 23626    75     6  2930     3  1508   477 19741  1508 38914\n",
      "  1508  1508  4616   477     6     3    75 23626   279 19741 23626   279\n",
      " 38914 23626   279  4184   171   477    16     3    75    17  1508    11\n",
      " 23626  3491    36    94   270   386    36  1508  5987  3491    36  3491\n",
      " 11464    94   270   386 11464  1508  3491 11464  3491  2820    94   270\n",
      "   386  2820  1508  3491  2820  3491 16224    94   270   386 16224  1508\n",
      "  3491 16224  2565   171   477    16     3    75    17  3491   142    11\n",
      " 23626   320  3491   142     2     9     1    14    67     4   115    18\n",
      "   195  2633    17     7 15779    16   958    14    70    37  1463    17\n",
      "    94     1     1   166   127    26    15   594   123     1     1     4\n",
      "    44   122     6  2258    35     1     1   320     7   221  2292    80\n",
      "     6   270  1508    36    39  2820    14   243   112   210  1508    36\n",
      "   176     7   313    63   192     3   104    36   168    16     3   164\n",
      "   142  1871     3    36   131   210  1508    39   176     7   313     1\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "# actual tokenization using the tokenizer from above\n",
    "posts_train_tf = word_tokenizer.texts_to_sequences(posts_train)\n",
    "posts_test_tf = word_tokenizer.texts_to_sequences(posts_test)\n",
    "\n",
    "# padding to a maximal question length for all questions\n",
    "maxlen_posts = 1000\n",
    "posts_train_tf = pad_sequences(posts_train_tf, maxlen=maxlen_posts, padding=\"post\", truncating=\"post\")\n",
    "posts_test_tf = pad_sequences(posts_test_tf, maxlen=maxlen_posts, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "print(posts_train_tf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:47:51.849200Z",
     "start_time": "2017-11-17T11:47:49.263628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   53   296   218    14   378    11 15779    16   398     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    }
   ],
   "source": [
    "titles_train_tf = word_tokenizer.texts_to_sequences(titles_train)\n",
    "titles_test_tf = word_tokenizer.texts_to_sequences(titles_test)\n",
    "\n",
    "# padding to a maximal title length\n",
    "maxlen_titles = 50\n",
    "titles_train_tf = pad_sequences(titles_train_tf, maxlen=maxlen_titles, padding=\"post\", truncating=\"post\")\n",
    "titles_test_tf = pad_sequences(titles_test_tf, maxlen=maxlen_titles, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "print(titles_train_tf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T10:59:50.885649Z",
     "start_time": "2017-11-17T10:59:49.624738Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting up weights matrix for embedding in keras\n",
    "weights_matrix = np.zeros((max_features + 1, embed_dim))\n",
    "\n",
    "for word, i in word_tokenizer.word_index.items():\n",
    "\n",
    "    if i > max_features:\n",
    "        continue\n",
    "    try:\n",
    "#         embedding_vector = embedding_vectors.get(word)\n",
    "        embedding_vector = gensimmodel.word_vec(word)\n",
    "        if embedding_vector is not None:\n",
    "            weights_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        weights_matrix[i] = np.zeros(embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:00:40.738323Z",
     "start_time": "2017-11-17T11:00:40.734459Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 20\n",
    "split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:01:29.968852Z",
     "start_time": "2017-11-17T11:01:29.763048Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting up posts branch for modeling\n",
    "posts_input = Input(shape=(maxlen_posts,), name=\"posts_input\")\n",
    "posts_embedding = Embedding(max_features + 1, embed_dim, weights=[weights_matrix])(posts_input)\n",
    "posts_pooling = GlobalAveragePooling1D()(posts_embedding)\n",
    "\n",
    "aux_output = Dense(1, activation=\"sigmoid\", name=\"aux_out\")(posts_pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:04:06.048149Z",
     "start_time": "2017-11-17T11:04:05.853191Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting up posts branch for modeling\n",
    "titles_input = Input(shape=(maxlen_titles,), name=\"titles_input\")\n",
    "titles_embedding = Embedding(max_features + 1, embed_dim, weights=[weights_matrix])(titles_input)\n",
    "titles_pooling = GlobalAveragePooling1D()(titles_embedding)\n",
    "\n",
    "aux_output2 = Dense(1, activation=\"sigmoid\", name=\"aux_out2\")(titles_pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:04:20.703497Z",
     "start_time": "2017-11-17T11:04:20.640581Z"
    }
   },
   "outputs": [],
   "source": [
    "# adding embeddings for other features\n",
    "relcols = [\"BodyNCodes\", \"BodyNQMarks\", \"BodySize\", \"titlelen\", \"nwords\", \"ordersum\", \"ordermean\", \"orderstd\", \"ratio\"]\n",
    "# todo: extend here to actually add all needed embeddings in dynamic way\n",
    "\n",
    "meta_embedding_dims = 64\n",
    "\n",
    "hours_input = Input(shape=(1,), name=\"hours_input\")\n",
    "hours_embedding = Embedding(24, meta_embedding_dims)(hours_input)\n",
    "hours_reshape = Reshape((meta_embedding_dims,))(hours_embedding)\n",
    "\n",
    "dayofweeks_input = Input(shape=(1,), name=\"dayofweeks_input\")\n",
    "dayofweeks_embedding = Embedding(7, meta_embedding_dims)(dayofweeks_input)\n",
    "dayofweeks_reshape = Reshape((meta_embedding_dims,))(dayofweeks_embedding)\n",
    "\n",
    "dayofyears_input = Input(shape=(1,), name=\"dayofyears_input\")\n",
    "dayofyears_embedding = Embedding(366, meta_embedding_dims)(dayofyears_input)\n",
    "dayofyears_reshape = Reshape((meta_embedding_dims,))(dayofyears_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:04:27.019438Z",
     "start_time": "2017-11-17T11:04:26.946604Z"
    }
   },
   "outputs": [],
   "source": [
    "# connecting the different embeddings\n",
    "merged = concatenate([posts_pooling, titles_pooling, hours_reshape, dayofweeks_reshape, dayofyears_reshape])\n",
    "\n",
    "hidden_1 = Dense(256, activation=\"relu\")(merged)\n",
    "hidden_1 = BatchNormalization()(hidden_1)\n",
    "\n",
    "main_output = Dense(1, activation=\"sigmoid\", name=\"main_out\")(hidden_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:04:37.950589Z",
     "start_time": "2017-11-17T11:04:37.824956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts_input (InputLayer)        (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "titles_input (InputLayer)       (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hours_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dayofweeks_input (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dayofyears_input (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 300)    15000300    posts_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 50, 300)      15000300    titles_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 64)        1536        hours_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 64)        448         dayofweeks_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 64)        23424       dayofyears_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 300)          0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 300)          0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 64)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 64)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 64)           0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 792)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          203008      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_out (Dense)                (None, 1)            257         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "aux_out (Dense)                 (None, 1)            301         global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "aux_out2 (Dense)                (None, 1)            301         global_average_pooling1d_4[0][0] \n",
      "==================================================================================================\n",
      "Total params: 30,230,899\n",
      "Trainable params: 30,230,387\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[posts_input,\n",
    "                      titles_input,\n",
    "                      hours_input,\n",
    "                      dayofweeks_input,\n",
    "                      dayofyears_input], outputs=[main_output, aux_output, aux_output2])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"],\n",
    "              loss_weights=[1, 0.2, 0.2])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-16T15:13:05.276583Z",
     "start_time": "2017-11-16T15:13:04.447887Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='./plots/keras_model.png')\n",
    "plot_model(model, to_file='./plots/model_shapes.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:04:51.657713Z",
     "start_time": "2017-11-17T11:04:51.630481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50104 (100000,)\n",
      "0.49896\n",
      "0.50208\n",
      "0.50305\n",
      "0.5049\n"
     ]
    }
   ],
   "source": [
    "print np.sum(qstrain[label]), qstrain[label].shape\n",
    "print 1 - np.sum(qstrain[label]) * 1. / qstrain[label].shape[0]\n",
    "print 1 - np.sum(qstest[label]) * 1. / qstest[label].shape[0]\n",
    "print(1 - np.mean(qstrain[label][:(int(posts_train_tf.shape[0] * split))]))\n",
    "print(1 - np.mean(qstest[label][:(int(posts_test_tf.shape[0] * split))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:05:11.253413Z",
     "start_time": "2017-11-17T11:05:11.246705Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:46:35.585066Z",
     "start_time": "2017-11-17T11:05:35.617929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/5\n",
      "80000/80000 [==============================] - 455s 6ms/step - loss: 0.4981 - main_out_loss: 0.2519 - aux_out_loss: 0.6255 - aux_out2_loss: 0.6056 - main_out_acc: 0.9023 - aux_out_acc: 0.7514 - aux_out2_acc: 0.7765 - val_loss: 0.4222 - val_main_out_loss: 0.2119 - val_aux_out_loss: 0.5500 - val_aux_out2_loss: 0.5018 - val_main_out_acc: 0.9204 - val_aux_out_acc: 0.8600 - val_aux_out2_acc: 0.8495\n",
      "Epoch 2/5\n",
      "80000/80000 [==============================] - 480s 6ms/step - loss: 0.3237 - main_out_loss: 0.1409 - aux_out_loss: 0.4927 - aux_out2_loss: 0.4216 - main_out_acc: 0.9536 - aux_out_acc: 0.8677 - aux_out2_acc: 0.8561 - val_loss: 0.3599 - val_main_out_loss: 0.1979 - val_aux_out_loss: 0.4390 - val_aux_out2_loss: 0.3710 - val_main_out_acc: 0.9258 - val_aux_out_acc: 0.8963 - val_aux_out2_acc: 0.8668\n",
      "Epoch 3/5\n",
      "80000/80000 [==============================] - 500s 6ms/step - loss: 0.2490 - main_out_loss: 0.1054 - aux_out_loss: 0.3945 - aux_out2_loss: 0.3231 - main_out_acc: 0.9666 - aux_out_acc: 0.8956 - aux_out2_acc: 0.8826 - val_loss: 0.2966 - val_main_out_loss: 0.1601 - val_aux_out_loss: 0.3668 - val_aux_out2_loss: 0.3155 - val_main_out_acc: 0.9481 - val_aux_out_acc: 0.9138 - val_aux_out2_acc: 0.8730\n",
      "Epoch 4/5\n",
      "80000/80000 [==============================] - 506s 6ms/step - loss: 0.2058 - main_out_loss: 0.0845 - aux_out_loss: 0.3287 - aux_out2_loss: 0.2779 - main_out_acc: 0.9733 - aux_out_acc: 0.9115 - aux_out2_acc: 0.8953 - val_loss: 0.3081 - val_main_out_loss: 0.1851 - val_aux_out_loss: 0.3208 - val_aux_out2_loss: 0.2947 - val_main_out_acc: 0.9473 - val_aux_out_acc: 0.9074 - val_aux_out2_acc: 0.8783\n",
      "Epoch 5/5\n",
      "80000/80000 [==============================] - 518s 6ms/step - loss: 0.1751 - main_out_loss: 0.0672 - aux_out_loss: 0.2864 - aux_out2_loss: 0.2534 - main_out_acc: 0.9784 - aux_out_acc: 0.9212 - aux_out2_acc: 0.9041 - val_loss: 0.3421 - val_main_out_loss: 0.2250 - val_aux_out_loss: 0.2988 - val_aux_out2_loss: 0.2870 - val_main_out_acc: 0.9395 - val_aux_out_acc: 0.8948 - val_aux_out2_acc: 0.8788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0396c77b90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting :)\n",
    "model.fit([posts_train_tf, titles_train_tf, qstrain.dayhour.values, qstrain.weekday.values, qstrain.day.values],\n",
    "          [qstrain[label], qstrain[label], qstrain[label]],\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_split=split, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:48:44.950712Z",
     "start_time": "2017-11-17T11:48:06.936303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s 760us/step\n"
     ]
    }
   ],
   "source": [
    "a = model.evaluate(x=[posts_test_tf, titles_test_tf, qstest.dayhour.values, qstest.weekday.values, qstest.day.values],\n",
    "                   y=[qstest[label], qstest[label], qstest[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T13:27:49.998308Z",
     "start_time": "2017-11-17T13:27:49.124686Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"keras_ispython.nnmodel\")\n",
    "model.save_weights(\"keras_ispython_weights.nnmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T11:49:05.399713Z",
     "start_time": "2017-11-17T11:49:05.393527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35052877676486971, 0.23091761281058193, 0.30452059776306151, 0.29353521305084229, 0.93891999999999998, 0.89156000000000002, 0.87805999999999995]\n"
     ]
    }
   ],
   "source": [
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T16:23:24.387602Z",
     "start_time": "2017-11-14T16:23:24.381893Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T16:27:40.694006Z",
     "start_time": "2017-11-14T16:27:40.681193Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_bin = np.around(preds).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-14T16:29:09.531100Z",
     "start_time": "2017-11-14T16:29:09.522517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88057\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "print np.sum(preds_bin == label)\n",
    "print len(preds_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "535px",
    "left": "996px",
    "right": "20px",
    "top": "120px",
    "width": "336px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
